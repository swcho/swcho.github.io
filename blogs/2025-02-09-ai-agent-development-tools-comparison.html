<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="initial-scale=1.0, width=device-width" data-next-head=""/><title data-next-head="">AI 에이전트 개발 도구 탐험: LangChain, Dify, Vercel AI SDK 비교</title><link rel="preload" href="/_next/static/css/d20c50ed748cd26f.css" as="style"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/vs2015.min.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous"/><link rel="stylesheet" href="/_next/static/css/d20c50ed748cd26f.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-0b9df2340104f8e1.js" defer=""></script><script src="/_next/static/chunks/framework-80cff53c93df8ff7.js" defer=""></script><script src="/_next/static/chunks/main-beade485850481f6.js" defer=""></script><script src="/_next/static/chunks/pages/_app-5b36dff9503cb490.js" defer=""></script><script src="/_next/static/chunks/5695-9c01eff236121af5.js" defer=""></script><script src="/_next/static/chunks/pages/blogs/2025-02-09-ai-agent-development-tools-comparison-220b32fa1135018c.js" defer=""></script><script src="/_next/static/qfjDRDkI7hbaUN0YCN0K0/_buildManifest.js" defer=""></script><script src="/_next/static/qfjDRDkI7hbaUN0YCN0K0/_ssgManifest.js" defer=""></script><style id="__jsx-4134105190">.markdown html{font:118.75%/1.58 'Roboto',serif;box-sizing:border-box;overflow-y:scroll;}.markdown *{box-sizing:inherit;}.markdown *:before{box-sizing:inherit;}.markdown *:after{box-sizing:inherit;}.markdown body{color:hsla(0,0%,0%,0.73);font-family:'Roboto',serif;font-weight:400;word-wrap:break-word;font-kerning:normal;-moz-font-feature-settings:"kern", "liga", "clig", "calt";-ms-font-feature-settings:"kern", "liga", "clig", "calt";-webkit-font-feature-settings:"kern", "liga", "clig", "calt";font-feature-settings:"kern", "liga", "clig", "calt";}.markdown img{max-width:100%;margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown h1{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;color:hsla(0,0%,0%,0.9);font-family:'Roboto Slab',sans-serif;font-weight:700;text-rendering:optimizeLegibility;font-size:2rem;line-height:1.1;}.markdown h2{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;color:hsla(0,0%,0%,0.9);font-family:'Roboto Slab',sans-serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1.51572rem;line-height:1.1;}.markdown h3{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;color:hsla(0,0%,0%,0.9);font-family:'Roboto Slab',sans-serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1.31951rem;line-height:1.1;}.markdown h4{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;color:hsla(0,0%,0%,0.9);font-family:'Roboto Slab',sans-serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1rem;line-height:1.1;}.markdown h5{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;color:hsla(0,0%,0%,0.9);font-family:'Roboto Slab',sans-serif;font-weight:700;text-rendering:optimizeLegibility;font-size:0.87055rem;line-height:1.1;}.markdown h6{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;color:hsla(0,0%,0%,0.9);font-family:'Roboto Slab',sans-serif;font-weight:700;text-rendering:optimizeLegibility;font-size:0.81225rem;line-height:1.1;}.markdown hgroup{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown ul{margin-left:1.58rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;list-style-position:outside;list-style-image:none;}.markdown ol{margin-left:1.58rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;list-style-position:outside;list-style-image:none;}.markdown dl{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown dd{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown p{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown figure{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown pre{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;font-size:0.85rem;line-height:1.58rem;}.markdown table{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;font-size:1rem;line-height:1.58rem;border-collapse:collapse;width:100%;}.markdown fieldset{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown blockquote{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;font-size:0.94737rem;line-height:1.58rem;border-left:0.5925rem solid #017698;color:hsla(0,0%,0%,0.65);background-color:hsla(0,0%,0%,0.1);padding:0.29625rem 0.9875rem;font-style:italic;}.markdown form{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown noscript{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown iframe{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown hr{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:calc(1.58rem - 1px);background:hsla(0,0%,0%,0.2);border:none;height:1px;}.markdown address{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.58rem;}.markdown b{font-weight:700;}.markdown strong{font-weight:700;}.markdown dt{font-weight:700;}.markdown th{font-weight:700;}.markdown li{margin-bottom:calc(1.58rem / 2);}.markdown ol li{padding-left:0;}.markdown ul li{padding-left:0;}.markdown li > ol{margin-left:1.58rem;margin-bottom:calc(1.58rem / 2);margin-top:calc(1.58rem / 2);}.markdown li > ul{margin-left:1.58rem;margin-bottom:calc(1.58rem / 2);margin-top:calc(1.58rem / 2);}.markdown blockquote *:last-child{margin-bottom:0;}.markdown li *:last-child{margin-bottom:0;}.markdown p *:last-child{margin-bottom:0;}.markdown li > p{margin-bottom:calc(1.58rem / 2);}.markdown code{font-size:0.85rem;line-height:1.58rem;}.markdown kbd{font-size:0.85rem;line-height:1.58rem;}.markdown samp{font-size:0.85rem;line-height:1.58rem;}.markdown abbr{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}.markdown acronym{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}.markdown abbr[title]{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;text-decoration:none;}.markdown thead{text-align:left;}.markdown td,th{text-align:left;border-bottom:1px solid hsla(0,0%,0%,0.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding-left:1.05333rem;padding-right:1.05333rem;padding-top:0.79rem;padding-bottom:calc(0.79rem - 1px);}.markdown th:first-child,td:first-child{padding-left:0;}.markdown th:last-child,td:last-child{padding-right:0;}.markdown a{color:#017698;text-decoration:none;background-image:linear-gradient(to top, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0) 1px, #017698 1px, #017698 2px, rgba(0, 0, 0, 0) 2px);}.markdown a:hover,a:active{text-shadow:none;background-image:none;}.markdown h1,h2,h3,h4,h5,h6{margin-top:3.16rem;}.markdown li>ol,li>ul{margin-left:20px;margin-bottom:0;}.markdown blockquote > :last-child{margin-bottom:0;}.markdown blockquote cite{font-size:1rem;line-height:1.58rem;color:hsla(0,0%,0%,0.73);font-style:normal;font-weight:400;}.markdown blockquote cite:before{content:"— ";}.markdown @media only screen and (max-width:480px){html{font-size:106.25%;line-height:28px;}blockquote{border-left:0.29625rem solid #017698;color:hsla(0,0%,0%,0.59);padding-left:0.88875rem;font-style:italic;margin-left:-1.185rem;margin-right:0;}} .markdown{color:#3d3d3d}.markdown ul li{list-style-type:disc}.markdown ol{list-style-type:decimal}:not(pre) code{background-color:rgb(203 208 218);border-radius:3px;font-family:D2Coding,Consolas,"Roboto Mono","Liberation Mono",Menlo,Courier,monospace;padding:.2rem .3rem;margin:0 .2rem}.markdown * code{font-size:inherit}.markdown code[class*="language-"]{font-family:D2Coding,Consolas,"Roboto Mono","Liberation Mono",Menlo,Courier,monospace;padding:1rem;background-color:#2d2d2d}</style></head><body><div id="__next"><div class="leading-normal tracking-normal bg-gray-100 min-h-screen"><nav class="w-full"><div id="progress" class="top-0 z-20 h-1" style="background:linear-gradient(to right, #4dc0b5 var(--scroll), transparent 0)"></div><div class="flex flex-wrap items-center justify-between w-full py-3 mx-auto mt-0 md:max-w-4xl"><div class="pl-4"><a class="text-xl font-extrabold text-gray-900 no-underline hover:no-underline" href="/">lifetime trails</a></div><div class="block pr-4 lg:hidden"><button id="nav-toggle" type="button" class="flex items-center px-3 py-2 text-gray-500 appearance-none hover:text-gray-900 hover:border-teal-500 focus:outline-none"><svg class="w-3 h-3 fill-current" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"></path></svg></button></div><div id="nav-content" class="bg-gray-100 border-b flex-grow lg:border-none lg:flex lg:items-center lg:mt-0 lg:shadow-none lg:w-auto md:bg-transparent mt-2 shadow w-full z-20 hidden"><ul class="items-center justify-end flex-1 list-reset lg:flex"><li class="mr-3"><a class="inline-block text-gray-600 no-underline hover:text-gray-900 hover:text-underline py-2 px-4" href="/">Home</a></li></ul></div></div></nav><div class="container w-full px-4 pb-10 mx-auto md:max-w-3xl"><h1 class="font-bold text-gray-800 mb-4 text-5xl mt-8 mb-8">AI 에이전트 개발 도구 탐험: LangChain, Dify, Vercel AI SDK 비교</h1><div class="details"><p class="text-gray-500">LLM 애플리케이션 개발을 위한 다양한 도구들의 장단점을 살펴보고 Vercel AI SDK를 선택한 과정을 공유합니다.</p><p class="text-gray-400 text-right -mt-1"><span class="mr-4">2025-02-09</span></p></div><article class="markdown"><h1>소개</h1>
<p><strong>이제 LLM의 생태계를 들여다 봐야할 시점이 왔습니다.</strong></p>
<p>LLM으로 인한 개발 환경 변화가 다가오고 있습니다.
오픈소스인 DeepSeek은 자유롭게 사용 및 배포 가능하고 Ollama를 사용해 PC에서도 구동해 볼 수 있기 때문입니다.</p>
<p>LangChain, Dify, Vercel AI sdk 순으로 살펴 보면서 어떤 준비를 해야할지 고민해 봅니다.</p>
<h1>LLM 애플리케이션 개발 툴</h1>
<p>LLM 활용의 대표적인 방식은 agent를 만드는 것 입니다.</p>
<p>결국 agent, workflow 등을 작성하는 tool, platform, library를 파악하고 집중해야 할 기술 방향을 모색해야 합니다.</p>
<h2>LangChain over engineered</h2>
<p>LLM 애플리케이션 개발 분야를 가장 발빠르게 선점한 솔루션은 LangChain 입니다.
Python과 JS/TS SDK를 오픈소스로 제공하면서 model 추상화, prompt templating, RAG 구축의 헤게모니를 넓혀오고 있습니다.</p>
<p>하지만 이전 포스팅에서 평가 했듯이 langchain의 과도한 추상화로 인해 본질적인 prompt 작성 보다는 SDK의 클래스와 용처를 파악하는데 시간을 쏟아야 했습니다.</p>
<blockquote>
<ul>
<li><a href="http://localhost/blogs/2023-06-18-langchainjs-part-1">LangchainJS 리뷰 #1</a></li>
<li><a href="http://localhost/blogs/2023-07-08-langchainjs-part-2">LangchainJS 리뷰 #2</a></li>
<li><a href="http://localhost/blogs/2023-07-15-langchainjs-part-3">LangchainJS 리뷰 #3</a></li>
</ul>
</blockquote>
<h2>Dify</h2>
<p>최근 테디노트님의 다음 영상을 통해 Dify를 알게되었습니다.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/OTsf94r_BkQ?si=oyFlBN6sgIcpIKr4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe>
<p>Dify는 AI Agent를 만드는 no code 툴로서 model 추상화, prompt templating, RAG는 물론 agent를 위한 tool 기능까지 매우 잘 다듬어진 솔루션입니다.</p>
<p>LLM 애플리케이션 개발을 이해하기 위해서라도 한번 즈음 사용해 볼 것을 추천 드립니다.</p>
<p>Agent, Chat flow, Workflow 등의 형태로 LLM 애플리케이션을 만들 수 있고 단일 WebApp, embedding, API 등의 형식으로 원클릭 배포할 수 있습니다.</p>
<p>또한, Model 비교 평가, Logging, Monitoring 등의 기능도 가지고 있습니다.</p>
<p>다시말해, LLM 애플리케이션을 no code 형식으로 개발, 평가, 배포, 운영할 수 있는 플렛폼의 면모를 가지고 있습니다.</p>
<h3>Knowledge (aka RAG)</h3>
<p>먼저 RAG의 경우 PDF, Word, Excel, Markdown 파일 등을 자유롭게 업로드할 수 있습니다.</p>
<p>텍스트의 splitting, chunking 설정, parent-child, reranking 까지 RAG를 모르는 사람도 UI를 통해 손쉽게 knowledge base를 구축할 수 있습니다.</p>
<p>생성한 Knowledge는 공용으로 접근 가능하여 LLM 애플리케이션에서 자유롭게 연동하여 사용할 수 있습니다.</p>
<h3>Knowledge Extension</h3>
<p>Dify는 REST 방식의 확장을 지원합니다.</p>
<blockquote>
<p><a href="https://docs.dify.ai/guides/knowledge-base/external-knowledge-api-documentation">External Knowledge API | Dify</a></p>
</blockquote>
<p>다음과 같은 형식의 API를 구현하면 됩니다.</p>
<pre><code>POST &lt;your-endpoint&gt;/retrieval
</code></pre>
<p>따라서, 사내에서 사용하고 있는 여러 검색 API와 연동할 수 있습니다.</p>
<p>Confluence, Jira, Github Enterprise 등의 검색 API와 적절히 연동한다면 매우 유용한 검색 보조 도구를 구축할 수 있습니다.</p>
<h3>RAG 한계점</h3>
<p>RAG는 사용자 질문에 대한 텍스트 정보를 의미 기반의 vector 검색으로 찾은 뒤 LLM을 사용해 요약해 주는 기능 입니다.</p>
<p>따라서 <code>검색 대행과 요약</code>이라는 기능적인 한계점에 머무를 수 밖에 없습니다.</p>
<p>또한, LLM의 Knowledge 검색 호출 시점을 예측할 수 없고, 여러 Knowledge 중 어떠한 것을 선택하여 질의할지에 대해서도 힌트를 주기 어렵습니다.</p>
<h3>Tool</h3>
<p><code>Tool</code>을 사용할 수 있는 LLM 애플리케이션을 Agent라 합니다.</p>
<blockquote>
<p><a href="https://docs.dify.ai/guides/tools">Tools | Dify</a></p>
</blockquote>
<p>구글 검색, Stable diffusion 이미지 생성, 논문 검색 등 다양한 <code>Tool</code>을 사용할 수 있습니다.</p>
<p>각 Knowledge가 가진 정보를 명시적으로 기술하는 방식으로 LLM 호출을 유도할 수 있어 RAG의 한계점을 극복할 수 있습니다.</p>
<p>LLM에 정보를 주입하는 수동적인 동작에서 벗어나 보다 능동적인 행위를 하도록 확장할 수 있습니다.</p>
<h3>Tool Extension With Open API</h3>
<p><code>Tool</code> 역시 확장 가능합니다.</p>
<blockquote>
<p><a href="https://docs.dify.ai/guides/extension/api-based-extension/cloudflare-workers">Deploy API Tools with Cloudflare Workers | Dify</a></p>
</blockquote>
<p>다음과 같이 OpenAPI 3.0 버전의 문서 링크를 입력하는 것 만으로 Custom Tool을 생성하고 LLM 애플리케이션에서 활용할 수 있습니다.</p>
<p><img alt="custom tool" loading="lazy" width="1248" height="1704" decoding="async" data-nimg="1" class="shadow" style="color:transparent;width:100%;height:auto" src="/_next/static/media/image.4db06397.png"/></p>
<h3>Dify의 한계점</h3>
<p>만들고자 하는 LLM 애플리케이션의 원하는 동작이나 기능을 위한 Agent나 Workflow 개발이 필요합니다.</p>
<p><img alt="workflow" loading="lazy" width="1328" height="896" decoding="async" data-nimg="1" class="shadow" style="color:transparent;width:100%;height:auto" src="/_next/static/media/image-1.d96c885a.png"/></p>
<p>복잡한 시나리오 및 edge case 개발, prompt, tool 유지보수 모두를 UI를 통해서 진행해야 합니다.</p>
<p>개발자에게는 node graph 기반의 no coding 툴은 과유불급 입니다.</p>
<p>Workflow 개발을 위한 node graph의 조합이라는 행위는 근본적으로 programming을 모사한 것이기 때문입니다.
로직 분기, 병렬 처리, iteration은 모두 프로그래밍 랭귀지의 속성이며 no code 툴은 이를 시각적으로 옯겨놓은 것에 불과합니다.
각 node를 이해하고 연관을 맺는 시간에 익숙한 언어로 빠르게 코딩하고 유지보수하는 것이 현명한 선택 입니다.</p>
<p>또한 힘들게 만든 Workflow의 prompt와 처리 로직 정보는 Dify에 lock in 됩니다.
Dify 툴이 영원히 존재할지도 모르고 더 좋은 툴이 생길 수도 있습니다.
따라서 이식성(Portability)을 고려한 개발 환경을 선택하는 것이 바람직 합니다.</p>
<p>결국엔 Dify의 강점인 no code가 약점이 됩니다.</p>
<h2>Vercel AI-SDK</h2>
<p>LangChain의 복잡성 없이 code 기반의 LLM 애플리케이션을 구축할 수 있는 대안이 필요합니다.</p>
<p>그리고 그 대안은 단 5줄의 코드로 설명가능합니다.</p>
<pre><code class="language-ts">import { generateText } from &#x27;ai&#x27;;
import { openai } from &#x27;@ai-sdk/openai&#x27;;

const { text } = await generateText({
  model: openai(&#x27;o3-mini&#x27;),
  prompt: &#x27;What is love?&#x27;,
});
</code></pre>
<p>이제 마우스 클릭의 과사용으로 인한 어깨 결림에서 탈출할 수 있습니다.</p>
<p>Code 기반이기에 version control, pull request를 통한 이력관리 및 변경통제가 가능해 집니다.</p>
<h3>Model abstraction</h3>
<blockquote>
<p><a href="https://sdk.vercel.ai/docs/foundations/providers-and-models">Foundations: Providers and Models</a></p>
</blockquote>
<p>OpenAPI, Anthropic, Ollama 등의 LLM을 동일한 인터페이스로 사용할 수 있습니다.</p>
<h3>Prompting</h3>
<blockquote>
<p><a href="https://sdk.vercel.ai/docs/foundations/prompts">Foundations: Prompts</a></p>
</blockquote>
<p>minimal하고 직관적인 프롬프트 작성 환경을 제공합니다.</p>
<p><a href="https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Template_literals">Template literals</a>만으로 충분합니다.</p>
<h3>Agent tool</h3>
<blockquote>
<p><a href="https://sdk.vercel.ai/docs/foundations/tools">Foundations: Tools</a></p>
</blockquote>
<p><a href="https://github.com/transitive-bullshit/agentic">transitive-bullshit/agentic</a>와 같은 Toolkit을 쉽고 빠르게 연동할 수 있습니다.</p>
<pre><code class="language-ts">// sdk-specific imports
import { openai } from &#x27;@ai-sdk/openai&#x27;;
import { generateText } from &#x27;ai&#x27;;
import { createAISDKTools } from &#x27;@agentic/ai-sdk&#x27;;

// sdk-agnostic imports
import { WeatherClient } from &#x27;@agentic/stdlib&#x27;;

const weather = new WeatherClient();

const result = await generateText({
  model: openai(&#x27;gpt-4o-mini&#x27;),
  // this is the key line which uses the `@agentic/ai-sdk` adapter
  tools: createAISDKTools(weather),
  toolChoice: &#x27;required&#x27;,
  prompt: &#x27;What is the weather in San Francisco?&#x27;,
});

console.log(result.toolResults[0]);
</code></pre>
<p>물론 직접 Tool을 만들어도 되겠습니다. 😉</p>
<h3>Ecosystem</h3>
<p>Vercel AI SDK는 과하지 않은 라이브러리 입니다.</p>
<p>Vercel이라는 회사가 개발을 하고 있어 프로젝트에 대한 끊임없는 개선을 기대할 수 있습니다.</p>
<p>따라서 model provider, toolkit의 다양한 확장이 community 중심으로 이루어 지고 있습니다.</p>
<h1>마치며</h1>
<p>LangChain, Dify, Vercel AI SDK를 거치면서 어떤 관점에서 기술셋을 선정하고 준비해야 하는지 설명했습니다.</p>
<p>같은 관점에서 보았을 때, LangChain을 중심으로 하거나(LangGraph), No code 툴(Flowise, n8n)을 사용한 LLM 애플리케이션 개발은 기술적 한계와 확장성 측면에서 신중하게 접근해야 합니다.</p>
<p>Vercel AI SDK는 과하지 않은 라이브러리 입니다.
교만하게 제안하거나 욕심으로 자신의 서비스에 가두려 하지 않습니다.</p>
<p>그리고 이렇게 간단하고 단단한 기반이 있기에 <a href="https://axar-ai.gitbook.io/axar">AXAR AI</a> 같은 신선한 시도가 가능하다고 생각합니다.</p>
<pre><code class="language-ts">import { model, systemPrompt, Agent } from &#x27;@axarai/axar&#x27;;

// Define the agent.
@model(&#x27;openai:gpt-4o-mini&#x27;)
@systemPrompt(&#x27;Be concise, reply with one sentence&#x27;)
export class SimpleAgent extends Agent&lt;string, string&gt; {}

// Run the agent.
async function main() {
  const response = await new SimpleAgent().run(&#x27;Where does &quot;hello world&quot; come from?&#x27;);
  console.log(response);
}

main().catch(console.error);
</code></pre>
<p>물론, Dify와 같이 Deploy, Logging, Monitoring과 같은 기능은 제공하지 않습니다.</p>
<p>하지만, <a href="https://sdk.vercel.ai/providers/ai-sdk-providers">AI SDK Providers</a>에서 살펴볼 수 있듯 다양한 서비스와 연동할 수 있습니다.</p>
<p>종종 React 개발 환경의 파편화를 비판적인 시각으로 바라보는 경우가 있습니다.</p>
<p>파편화를 다르게 생각하면 다양성의 수용입니다.</p>
<p>다양성을 수용한 Vercel AI SDK를 선택하고 집중하려 합니다.</p></article><div class="react-utterences"><div>Loading script...</div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/blogs/2025-02-09-ai-agent-development-tools-comparison","query":{},"buildId":"qfjDRDkI7hbaUN0YCN0K0","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>